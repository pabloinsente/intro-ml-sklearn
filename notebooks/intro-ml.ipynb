{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents in this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied Machine learning**\n",
    "\n",
    "- [What is machine learning](#what-is-machine-learning)\n",
    "- [When to use machine learning](#when-to-use-machine-learning)\n",
    "    - [When the solution is unknown](#when-the-solution-is-unknown)\n",
    "    - [When the solution is known but too costly](#when-the-solution-is-known-but-too-costly)\n",
    "    - [When an imperfect solution is acceptable](#when-an-imperfect-solution-is-acceptable)\n",
    "    - [When an imperfect explanation is acceptable](#when-an-imperfect-explanation-is-acceptable)\n",
    "    - [When the solution changes over time at relatively fast pace](#when-the-solution-changes-over-time-at-relatively-fast-pace)\n",
    "    - [When large amounts of data are available or can be collected](#when-large-amounts-of-data-are-available-or-can-be-collected)\n",
    "- [Prerequisites for applied machine learning](#prerequisites-for-applied-machine-learning)\n",
    "- Types of machine learning\n",
    "    - Supervised learning \n",
    "    - Unsupervised learning\n",
    "    - Semi-supervised learning\n",
    "    - Reinforcement learning\n",
    "- Components of learning algorithms\n",
    "    - Information: training and testing data\n",
    "    - Representation of the solution: model\n",
    "    - Metric of success: cost function\n",
    "    - Self-adjusting mechanism: learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple definitions of machine learning have been offered since its inception. Here is Arthur Samuel's (1959) definition:\n",
    "\n",
    "```\n",
    "\"field of study that gives computers the ability to learn without being explicitly programmed\"\n",
    "```\n",
    "\n",
    "Samuel's definition is similar to many others you can find in popular textbooks. It describes machine learning in opposition to traditional programming that requires humans figuring it out solutions for problems by themselves and then manually incorporate such solutions into the system. Machine learning, in contrast, are systems that find solutions for you. The role of designers is to set up a system capable of finding solutions based on data about the problem. \n",
    "Consider microwaves and spam filters: in the first case, programmers and engineers figure out the problem (i.e., heating food safely) beforehand and then codify the solution into the microwave; in the second case, programmers and engineers collect data and set up a learning system that will found the best possible solution automatically, without having to codify a set of rules and step to follow for the system. \n",
    "\n",
    "That being said, I think the issue of what machine learning is requires a bit more discussion. \n",
    "\n",
    "I had always think on **learning** as something that only living organism do. Broadly speaking, in Psychology we understand **learning as changes in the contents of the mind and/or patterns of behavior in response to interactions with the environment.** Rocks don't learn, because they don't think or behave. Printers don't learn, because although they \"do things\", they do not have autonomy or volition of any kind. \"*But free will is an illusion, living things do no have autonomy anyways!*\" I do agree with the idea that, ultimately, living organism do not behave freely in the strict sense of the word. Yet, the point is that once a living organism pops into existence it can control and -importantly- adapt its own behavior in response to the environment. Here is where the notion of \"machine\" learning gets confusing. True, machines (let's leave the definition of machine aside for now) can \"react\" in response to the environment, but that does not seems to be enough. Thermostats reacts to the temperature changes in the environment by \"adjusting\" temperature information but that does not seems to be the notion of \"adjustment\" we are looking for. In short, reacting to the environment is not the same as adapting to it. **Machines reactions are more similar to human reflexes than learning**, and we do not understand reflexes as learning, as they are (mostly) static and innate.\n",
    "\n",
    "Reacting to the environment is not enough. **Machines need flexibility**. Here is where \"algorithms\" take an step-forward: as mathematical formulas, they do have **parameters** that can be adjusted in response to interacting with the environment (i.e., data). Coffee machines will (hopefully) the same thing each time you press the same button. A machine learning algorithm may or may not do the same thing each time you input the same data, as it contains the capacity of progressively adjust its \"behavior\".  \n",
    "\n",
    "There is more. Living organism do not adjust (at least not most of the time) randomly. They have **goals**. For our purposes, goals do not need to be conscious, just to be guiding forces driving behavioral change.  Worms have no capacity for conscious thinking, yet survival is an \"implicit goal\" guiding their behavior. Hence, flexible adjustment to the environment is not enough. **Machines need goals**. In machine learning jargon, goals are the so-called **objective function** (or target function, or cost function). True, machines have no awareness of such a \"goal\" and it was externally imposed by its designer, but follow them regardless: **minimizing or maximizing the objective function**. \n",
    "\n",
    "I have read several discussions around machine learning and deep learning that describe the machine learning systems as \"just an algebraic expression\" or \"just a function\". And they are right to some extent: machine learning algorithms ultimately are mathematical expressions,  like $y = m\\alpha  +  b$, and it is good to keep this in mind to not feel unnecessarily intimidated. But here is the catch: living organism are no different. Even human behavior could be described in a mathematical expression. The issue is that the level of complexity of human behavior it's so tremendous that we do not how, but in principle we could.  \n",
    "\n",
    "In summary, **machine learning is the art and science of creating algorithms that can flexibility adjust (its parameters) in response to interactions with the environment (data) to improve in some measure of success**. Although learning machines do not replicate the conditions, complexity and substance of living organism, utilizing this conceptualization helps to capture the essence and purpose of machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The widespread media attention to machine learning and artificial intelligence may convey the impression that all technology uses machine learning tot tackle every possible problem. Although is true most new technology probably uses some form of machine learning somewhere, the majority of the functions that electronic devices perform do not implement or require machine learning at all. Yes, many of the functions in your cellphone do implement some form of computer vision or speech recognition, but the rest is old fashion plain programming. My point here is: although it may be tempting to incorporate machine learning to every problem, that does not mean that everything should be approached in that manner, or that it is necessary at all. Here is an incomplete list of situations when utilizing machine learning can be a good idea:\n",
    "\n",
    "- When the solution is unknown \n",
    "- When the solution is known but too costly or technically unfeasible\n",
    "- When an imperfect solution is acceptable\n",
    "- When the solution changes over time at relatively fast pace\n",
    "- When large amounts of data are available or can be collected\n",
    "\n",
    "Let me justify this little list of circumstances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the solution is unknown "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many problems that we have figured out in the last century from computing or algorithmic perspective. There is no point on utilizing machine learning to build a tic-tac-toe bot or to compute the trajectory of a cannonball, as such problems have known solutions which can be implemented with relative ease with traditional programming. However, there is a large list of problems that do not have known solutions that are worth exploring with machine learning, for instance: \n",
    "\n",
    "- Speech recognition\n",
    "- Handwritten text recognition\n",
    "- Time-series prediction\n",
    "- Autonomous driving\n",
    "- School dropout\n",
    "- People's musical taste\n",
    "- Image recognition\n",
    "- Substance abuse\n",
    "- The game of Go/Baduk/Weiqui\n",
    "\n",
    "And the list goes on and on. Of course, **the fact that a problem does not have a known solution does not make it a good target for machine learning automatically, but it is a good starting point**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the solution is known but too costly or unfeasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some problems that, in theory, could be solved if we have enough time to compute. The game of \"Go\" or (\"Baduk\" in Korean or \"Weiqui\" in Chinese) could be solved by brute force, this is, by searching for all possible combinations of the game, if we had infinite time and computational capacity. But we don't. There many other similar problems that \"could be\" solved with enough resources. There is a whole field in computer science devoted to study and classify problems on the basis of its computational complexity. In other words, how much computing they require to be solved or if they possible to solve at all. Broadly speaking, problems can be classified as being \"P\" (solvable in polynomial time) or \"NP\" (probably not solvable in polynomial time). \n",
    "\n",
    "There is no need to go depth into the waters of computational complexity theory to approach machine learning. What you have to keep in mind is that **some problems are really hard to solve given high computational demands, and such cases may be worth exploring with machine learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When an imperfect solution is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use a calculator, you probably expect it to compute everything correctly always. A calculator that adds 2 + 2 correctly 99% of the time, even 99.99% of the time, is probably worthless. I bet you probably don't want to build a rocket launcher with 95% of accuracy, and that probably you do not want to launch 10,000 rockets just to collect data and compute its accuracy. In such cases, you most likely do not want to utilize machine learning, as learning-based algorithms rarely yield perfect results. Some degree of error is a fact of life with machine learning. Plain deterministic mathematics and physics are probably better alternatives. Put simply, **machine learning is a better option when some degree of error is acceptable**.\n",
    "\n",
    "How much error is acceptable must be determined in a case by case basis. Life or death decision probably must have a lower tolerance to error than predicting the next word you will type in your cellphone. You also have to consider that not all errors are created equal (more on this later), so you will have to balance the kind of error the systems incur in.\n",
    "\n",
    "Fortunately, **there are many problems where imperfect solutions are acceptable or at least better than no solution at all**, so there is plenty of room to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When an imperfect explanation is acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not always clear why machine learning algorithms behave as they behave. Some, like logistic regression, are transparent and easy to analyze, while others like neural network tend to be obscure and hard to analyze. As a rule of thumb, the bigger and the more non-linearities the system has, the hard to figure it the reasons why classifies an instance in a category or another. Although machine learning \"explainability\" has made important advances in recent years, it is often hard to gain insight into the inner workings of learning algorithms. **If such ambiguity is a serious problem for your problem at hand, you may either be careful to select a simple and transparent (but often less powerful) algorithm, or simply avoid machine learning altogether**. \n",
    "\n",
    "There are several cases where explainability can be critical: legal decisions, law enforcement decisions, health-related decisions, etc. In such cases, 88you will be wise of making sure that imperfect or incomplete explanations are acceptable**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the solution changes over time at relatively fast pace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why hand-crafted rule-based systems work well for problems with known solutions like building a calculator or tic-tac-toe bot, is that the **solution for the problem does not change**. Once you figure it out the solution, you can incorporate it into the system and you are done pretty much forever. \n",
    "\n",
    "There are a second class of problems that have solution that although change over time, for instance, when better algorithms are found, such changes occur relatively slowly, meaning that you do not need to reprogram the system every-week or every-month.  \n",
    "\n",
    "The real challenge are **problems for which the best solution changes constantly**. How can this be possible? It is nature of any complex dynamical system, and the world is full of complex dynamical systems. The economy, politics, culture, and human beings are dynamical systems. For instance, people's music preferences change all the time. Figuring out people's preferences in the autumn may no longer help you to predict people's preferences in the summer. The implication is that you have update your prediction engine periodically based on fresh data about user preferences. This is where machine learning thrives: **learning algorithms can be constantly retrained and redeployed based on the most up to date data about any problem, so they are your best bet in such scenarios**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When large amounts of data are available or can be collected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It goes without saying that machine learning applications are data hungry. How much data you will need is a another case by case type of decision, but roughly speaking you will from the order of several thousands (5,000 - 10,000) to several millions of data points. The type of algorithm selected, type of problem, accuracy requirements, generalization requirements, and other circumstances will determine how much data you will require. Simple models like linear regression usually can do a descent job with small datasets, but neural networks often require larger datasets. The only certainty is the more data the better, or at least does not hurt. \n",
    "\n",
    "**If relatively large amounts of data are not available or cannot be collected at reasonable cost for you, it is unlikely that machine learning will be of any use**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites for applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research in machine learning and applied machine learning have different prerequisites. Here I am concerned with the latter. Broadly speaking, applied machine learning has the following prerequisites:\n",
    "\n",
    "1. Intermediate level understanding of mathematical basis: linear algebra, calculus, probability theory, information theory, and optimization\n",
    "2. Intermediate level skills in programming and computer science fundamentals\n",
    "3. Training in applied research methods and scientific thinking\n",
    "\n",
    "In my experience, most people overemphasis the first two, particularly the second one. The third, in my opinion, is as important if not more important the first two. It is also hard to acquire as is something for which you will need a mentor, peers, and applied research opportunities. The easiest way to acquire those is via formal undergraduate and graduate level education, or via multiple internships and industry experience. Sometimes I see people, particularly recruiters and hiring managers, that believe that the best machine learning practitioner candidates are the ones that obtained a double major in mathematics and computer science from MIT or some other prestigious institution. I think they are deeply mistaken. There is nothing in the standard curricula of mathematics and CS majors conducting to develop the complex array of intellectual skills required for becoming a creative and effective expert in applied machine learning. What you need, is actual applied experience dealing with open-ended problems and the guidance of a mentor and peers. The reason why Math/CS graduates from prestigious institutions turn out to be good ML practitioners, I believe, is because they are usually highly skilled, ambitious, and fast-learners, so they adjust fast. \n",
    "\n",
    "Acquiring the first two skills may or may not be hard for you depending on your background and preferences, but they do have the advantage that are things that you can learn -mostly- on your own. I learned linear algebra on my own. My recipe was to grab a bunch of books and watch a lot of video-lectures. Doing it on your own can be though as no instructors, peers, or external structure is around you to help when your motivation wanes or you get stuck. But it is possible. \n",
    "\n",
    "In any case, whatever your resources or the order in which you decide to learn applied machine learning, I highly recommend putting effort in becoming proficient (not an expert) at those things: mathematical foundations, programming and CS foundations, and gather as much research experience and scientific training as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algorithms can interact with data (the \"environment\") in a wide variety of ways, and we can classify learning algorithms on such basis. **We said an algorithm learns in a \"supervised\" fashion when a\"trainer\" oversees and corrects its \"behavior\" explicitly**. This is done by providing the correct answer and nudging the algorithm into the right direction after each attempt. For instance, let's say you are \"training\" an algorithm to classify tropical fruits. Supervised learning algorithms need: (\n",
    "\n",
    "1) data describing the fruit  (\"features\" or \"variables\") ; (2) data describing the right answer (\"targets\"); (3) a way to assess the correctness of its answer (\"an objective or cost function\"); (4) and a way to adjust its \"behavior\" after each trial (\"learning procedure\"). \n",
    "\n",
    "if you're keen to mathematical formalism, we can use the following notation:\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "Supervised learning operates under the assumption that the collected samples are independent and identically distributed or **i.i.d.** To put this in lay terms, imagine you have a bucket of red and green marbels and you draw samples from it. To be independent, the probability of grabing a marbel, should not impact the probability of collecting any subsequent sample. Each time you grab a marbel from the bucket, this must occur at random. To be identically distributed, you must always sample marbels from the same bucket, and the contents of the bucket must not change in the process. If you were yo sample from a different bucket or the contents of your bucket change, for instance, you add more red marbels, you will not be sampling from the same distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information: training and testing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation of the solution: Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric of success: Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-adjusting mechanism: Learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('venv': venv)",
   "language": "python",
   "name": "python36864bitvenvvenve269670d94154a47aa0ba5a4660e02de"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
